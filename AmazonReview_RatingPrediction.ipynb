{"nbformat_minor": 1, "cells": [{"source": "# Sentiment Analysis and Rating Prediction From The Review Text", "cell_type": "markdown", "metadata": {}}, {"source": "Sentiment ananlysis and rating prediction are among the imporant machine learning topics that help companies find if the users are happy or unhappy with the service/product provided. The users write reviews of the products/services on various platforms, such as social networking websites like Facebook and Twitter, Blogs, and service offering websites. The ananlysis of such reviews to find the coustomer satisfaction will be helpful for companies to improve their products as well as the customer service.\n\nIn this project, I aim to build a machine learning system that will predict the user rating from his text review. Precisely, I will work on building the models for the following.\n\n1. Predict the users' sentiments (positive or negative).\n2. Predict his product/service rating on a scale of 1 to 5.\n\nI have already done the ETL in the other notebook. So here, I will just load the data prepare it for the model training, valiadation and testing and describe the deep learning model employed. In this notebook, I will just focus on the rating predcitction, i.e. mutliclass-classfication. For sentiment analysis, i.e. the binary classification, I have described the modeling in another notebook.", "cell_type": "markdown", "metadata": {}}, {"source": "So, let's just start with loading the required libraries.", "cell_type": "markdown", "metadata": {}}, {"source": "import numpy as np\nimport pandas as pd\nimport gzip\nimport glob\nimport os\nimport re", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 1}, {"source": "from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 2}, {"source": "from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, GRU, Convolution1D, Flatten, Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.utils.np_utils import to_categorical\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n"}], "execution_count": 3}, {"source": "## Loading the data from the CSV", "cell_type": "markdown", "metadata": {}}, {"source": "df_ReviewRating = pd.read_csv('AmazonBookReviews_Ratings.csv')\ndf_ReviewRating.shape", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "(484645, 3)"}, "execution_count": 5, "metadata": {}}], "execution_count": 5}, {"source": "lenthsStr = df_ReviewRating['reviewText'].apply(str).map(len)\nmaxlength = max(lenthsStr)\nmaxindex = lenthsStr[lenthsStr == maxlength].index[0]\nprint('The length of longest review text: '+ str(maxlength))\nprint('The index of review with maximum length: '+ str(maxindex))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "The length of longest review text: 499\nThe index of review with maximum length: 100\n"}], "execution_count": 7}, {"source": "## Spliting Data Set into Train, Validation and Test", "cell_type": "markdown", "metadata": {}}, {"source": "X_train, X_test, y_train, y_test = train_test_split(df_ReviewRating['reviewText'], df_ReviewRating['overall'], test_size=0.2, random_state=1)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 8}, {"source": "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 9}, {"source": "print(X_train.shape)\nprint(X_train[0:5])\nprint(y_train.shape)\nprint(y_train[0:5])\n\ndf_train = pd.concat([X_train, y_train], axis=1)\ndf_train.groupby('overall').count()/df_train.shape[0]*100", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(310172,)\n475274    Great story branch off of original. Need next ...\n459122    I teach a watercolor class at a college for se...\n229593    NIce collection of Destroyer novels.  You get ...\n201419    I love Chuck Klosterman's pop culture essays, ...\n279894    The writing is excellent.  Good characters and...\nName: reviewText, dtype: object\n(310172,)\n475274    5.0\n459122    5.0\n229593    5.0\n201419    5.0\n279894    5.0\nName: overall, dtype: float64\n"}, {"output_type": "execute_result", "data": {"text/plain": "         reviewText\noverall            \n1.0        3.418426\n2.0        3.944908\n3.0        9.165237\n4.0       22.491069\n5.0       60.980359", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n    </tr>\n    <tr>\n      <th>overall</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.0</th>\n      <td>3.418426</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>3.944908</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>9.165237</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>22.491069</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>60.980359</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "execution_count": 10, "metadata": {}}], "execution_count": 10}, {"source": "print(X_test.shape)\nprint(X_test[0:5])\nprint(y_test.shape)\nprint(y_test[0:5])\ndf_test = pd.concat([X_test, y_test], axis=1)\ndf_test.groupby('overall').count()/df_test.shape[0]*100", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(96929,)\n140694    Loved it. Once I started reading it I couldn't...\n401595    Slow and boring. Gay son, military dad and wea...\n155299    VERY GOOD!  Mix of historical and modern times...\n109577    A must read. What a wonderful twist to a LOVE ...\n137179    Pauline is a lovable heroine . She is truly he...\nName: reviewText, dtype: object\n(96929,)\n140694    5.0\n401595    2.0\n155299    5.0\n109577    5.0\n137179    3.0\nName: overall, dtype: float64\n"}, {"output_type": "execute_result", "data": {"text/plain": "         reviewText\noverall            \n1.0        3.481930\n2.0        4.004993\n3.0        9.040638\n4.0       22.472119\n5.0       61.000320", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n    </tr>\n    <tr>\n      <th>overall</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.0</th>\n      <td>3.481930</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>4.004993</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>9.040638</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>22.472119</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>61.000320</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "execution_count": 11, "metadata": {}}], "execution_count": 11}, {"source": "print(X_val.shape)\nprint(X_val[0:5])\nprint(y_val.shape)\nprint(y_val[0:5])\ndf_val = pd.concat([X_val, y_val], axis=1)\ndf_val.groupby('overall').count()/df_val.shape[0]*100", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "(77544,)\n264019    As a fan of Dawn's, I was anxious to read her ...\n118798    There are some real surprises in this one, one...\n377831    In my opinion, as a writer/artist myself, this...\n119666    This book is beautifully done, so easy to foll...\n405407    This is a good resource for some one who has l...\nName: reviewText, dtype: object\n(77544,)\n264019    5.0\n118798    5.0\n377831    5.0\n119666    5.0\n405407    4.0\nName: overall, dtype: float64\n"}, {"output_type": "execute_result", "data": {"text/plain": "         reviewText\noverall            \n1.0        3.429021\n2.0        3.987414\n3.0        9.274734\n4.0       22.308625\n5.0       61.000206", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n    </tr>\n    <tr>\n      <th>overall</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.0</th>\n      <td>3.429021</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>3.987414</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>9.274734</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>22.308625</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <td>61.000206</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "execution_count": 12, "metadata": {}}], "execution_count": 12}, {"source": "We see that the distribution of classess in train, validation and test set is representative of the resal data set.", "cell_type": "markdown", "metadata": {}}, {"source": "## Data Preparation  for Modeling", "cell_type": "markdown", "metadata": {}}, {"source": "In this step, we first tokenize the textual data into words and convert it into sequences of same length.", "cell_type": "markdown", "metadata": {}}, {"source": "### Tokenization", "cell_type": "markdown", "metadata": {}}, {"source": "%%time\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(df_ReviewRating['reviewText'])\n", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 21.3 s, sys: 285 ms, total: 21.6 s\nWall time: 21.6 s\n"}], "execution_count": 13}, {"source": "vocab_size = len(tokenizer.word_index) + 1\nvocab_size", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "156075"}, "execution_count": 14, "metadata": {}}], "execution_count": 14}, {"source": "%%time\nsequence_train = tokenizer.texts_to_sequences(X_train)\nsequence_test = tokenizer.texts_to_sequences(X_test)\nsequence_val = tokenizer.texts_to_sequences(X_val)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 15.2 s, sys: 240 ms, total: 15.4 s\nWall time: 15.4 s\n"}], "execution_count": 15}, {"source": "%%time\nX_train_pad = pad_sequences(sequence_train, maxlen=maxlength)\nX_test_pad = pad_sequences(sequence_test, maxlen=maxlength)\nX_val_pad = pad_sequences(sequence_val, maxlen=maxlength)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "CPU times: user 4.51 s, sys: 1.36 s, total: 5.86 s\nWall time: 5.84 s\n"}], "execution_count": 16}, {"source": "Let us convert the labels vector to a matrix (one-hot encoded) using to_categorical. The to_categorical expects the label to start from 0, so I changed the labels. Now, rating one is represented by 0 and five by 4.", "cell_type": "markdown", "metadata": {}}, {"source": "y_train_label = to_categorical(np.asarray(y_train - 1))\nprint(y_train[0:5])\ny_test_label = to_categorical(np.asarray(y_test - 1))\nprint(y_test[0:5])\ny_val_label = to_categorical(np.asarray(y_val - 1))\nprint(y_val[0:5])", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "475274    5.0\n459122    5.0\n229593    5.0\n201419    5.0\n279894    5.0\nName: overall, dtype: float64\n140694    5.0\n401595    2.0\n155299    5.0\n109577    5.0\n137179    3.0\nName: overall, dtype: float64\n264019    5.0\n118798    5.0\n377831    5.0\n119666    5.0\n405407    4.0\nName: overall, dtype: float64\n"}], "execution_count": 17}, {"source": "y_train_label[0:5]", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "array([[ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.]])"}, "execution_count": 43, "metadata": {}}], "execution_count": 43}, {"source": "## Model Training and Evaluation", "cell_type": "markdown", "metadata": {}}, {"source": "In this project, I decided to use three different deep learning models. The models and their evaluation follows.", "cell_type": "markdown", "metadata": {}}, {"source": "### GRU based Model", "cell_type": "markdown", "metadata": {}}, {"source": "# embedding_dimensions =  vocab_size**0.25\nembedding_dimensions = 100", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 45}, {"source": "Model definition ...", "cell_type": "markdown", "metadata": {}}, {"source": "model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dimensions, input_length=maxlength))\nmodel.add(GRU(units=32, dropout=0.2))\nmodel.add(Dense(5, activation='softmax'))\nprint(model.summary()) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 46}, {"source": "Model compilation and training ...", "cell_type": "markdown", "metadata": {}}, {"source": "%%time\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 47}, {"source": "%%time\nmodel.fit(X_train_pad, y_train_label,\n          batch_size=128,\n          epochs=5,\n          validation_data=(X_val_pad, y_val_label),\n         callbacks = [checkpoint, early_stop])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 48}, {"source": "Model evaluation ...", "cell_type": "markdown", "metadata": {}}, {"source": "scores = model.evaluate(X_test_pad, y_test_label, verbose=0) \nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 49}, {"source": "### LSTM basedModel", "cell_type": "markdown", "metadata": {}}, {"source": "Model definition ...", "cell_type": "markdown", "metadata": {}}, {"source": "model = Sequential() \nmodel.add(Embedding(vocab_size, embedding_dimensions, input_length=maxlength)) \nmodel.add(LSTM(100)) \nmodel.add(Dense(5, activation='softmax'))\nprint(model.summary()) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Model comiplation and training ...", "cell_type": "markdown", "metadata": {}}, {"source": "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "%%time\nmodel.fit(X_train_pad, y_train_label,\n          batch_size=128,\n          epochs=5,\n          validation_data=(X_val_pad, y_val_label))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Model evaluation ...", "cell_type": "markdown", "metadata": {}}, {"source": "scores = model.evaluate(X_test_pad, y_test_label, verbose=0) \nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accuracy: 67.02%\n"}], "execution_count": 55}, {"source": "### 1D CNN based Model ", "cell_type": "markdown", "metadata": {}}, {"source": "Model definition ...", "cell_type": "markdown", "metadata": {}}, {"source": "model = Sequential() \nmodel.add(Embedding(vocab_size, embedding_dimensions, input_length=maxlength)) \nmodel.add(Convolution1D(64, 3, padding='same'))\nmodel.add(Convolution1D(32, 3, padding='same'))\nmodel.add(Convolution1D(16, 3, padding='same'))\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(180,activation='sigmoid'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5, activation='softmax'))\nprint(model.summary()) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Model compilation and training ...", "cell_type": "markdown", "metadata": {}}, {"source": "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) ", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "%%time\nmodel.fit(X_train_pad, y_train_label,\n          batch_size=128,\n          epochs=5,\n          validation_data=(X_val_pad, y_val_label))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Model evaluation ...", "cell_type": "markdown", "metadata": {}}, {"source": "scores = model.evaluate(X_test_pad, y_test_label, verbose=0) \nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "## Conclusion", "cell_type": "markdown", "metadata": {}}, {"source": "We have trained three different deep learning models to predict the user ratings from the text of the review they wrote. ", "cell_type": "markdown", "metadata": {}}, {"source": "", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3.5 with Spark 2.1", "name": "python3-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}